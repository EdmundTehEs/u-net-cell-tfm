{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99756256",
   "metadata": {},
   "source": [
    "# Multi-Cell TFM + U-Net Pipeline\n",
    "This notebook loops over multiple cell folders to prepare a dataset for U-Net training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e4c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import torch\n",
    "import csv\n",
    "from tfm import TFM_Image_registration, TFM_displacement_tools, TFM_tools\n",
    "from utils import data_processing, UNeXt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03684c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where each subfolder contains one cell's data\n",
    "base_input_dir = \"input_data\"\n",
    "output_dir = \"example_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f98a2",
   "metadata": {},
   "source": [
    "## Step 1\u20132: Process Each Cell and Stack `.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c24016",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_filenames = []\n",
    "\n",
    "for folder in sorted(os.listdir(base_input_dir)):\n",
    "    cell_path = os.path.join(base_input_dir, folder)\n",
    "    if not os.path.isdir(cell_path): continue\n",
    "\n",
    "    print(f\"Processing {folder}...\")\n",
    "\n",
    "    # TFM steps\n",
    "    TFM_Image_registration.TFM_Image_registration(cell_path)\n",
    "    TFM_displacement_tools.TFM_optical_flow(cell_path)\n",
    "    TFM_tools.TFM_calculation(cell_path)\n",
    "    TFM_tools.cellmask_threshold(cell_path)\n",
    "\n",
    "    # Read all tif files\n",
    "    fx = tifffile.imread(os.path.join(cell_path, \"fx_0.tif\"))\n",
    "    fy = tifffile.imread(os.path.join(cell_path, \"fy_0.tif\"))\n",
    "    ux = tifffile.imread(os.path.join(cell_path, \"disp_u_0.tif\"))\n",
    "    uy = tifffile.imread(os.path.join(cell_path, \"disp_v_0.tif\"))\n",
    "    mask = tifffile.imread(os.path.join(cell_path, \"cellmask.tif\"))\n",
    "    forcemask = tifffile.imread(os.path.join(cell_path, \"forcemask.tif\"))\n",
    "    zyxin = tifffile.imread(os.path.join(cell_path, \"zyxin.tif\"))\n",
    "    actin = tifffile.imread(os.path.join(cell_path, \"actin.tif\"))\n",
    "\n",
    "    stack = np.stack([ux, uy, fx, fy, mask, forcemask, zyxin, actin], axis=0)\n",
    "    npy_name = f\"{folder}.npy\"\n",
    "    np.save(os.path.join(output_dir, npy_name), stack)\n",
    "    npy_filenames.append(npy_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce92d89",
   "metadata": {},
   "source": [
    "## Step 3: Create `dataset.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae287439",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(output_dir, \"dataset.csv\")\n",
    "with open(csv_path, \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"filename\"])\n",
    "    for name in npy_filenames:\n",
    "        writer.writerow([name])\n",
    "print(\"CSV created at:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5999fc",
   "metadata": {},
   "source": [
    "## Step 4: Train U-Net on All Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de722da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_processing.CellDataset(output_dir, csv_path)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNeXt.UNeXt().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 3\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        x = batch[\"image\"].to(device, dtype=torch.float32)\n",
    "        y = batch[\"label\"].to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
